Paint Battle
=======

Forked from A1rPun to try some reinforcement learning on this game.

# [Play](https://A1rPun.github.io/PaintBattle)

**How to play**
- Player 1 is pink
- Use the left & right arrow keys to move

Inspired by the original game **Battle Painters**
![original.jpg](/img/original.jpg)

# ğŸ¨ PaintBattleDQL: Deep Q-Learning Agent for a 2D Painting Game

**PaintBattleDQL** is a reinforcement learning project where an autonomous agent is trained using **Deep Q-Learning (DQL)** to play a 2D browser-based multiplayer painting game. The agent learns to **maximize canvas coverage** in a time-limited environment through intelligent navigation and strategic exploration.

> ğŸ§  Developed by Group 13 as part of the *Natural Computation Methods in Machine Learning (NCML)* course at Uppsala University, Spring 2025.

---

## ğŸš€ Project Highlights

- ğŸ•¹ï¸ Real-time WebSocket communication between the browser game and Python agent
- ğŸ§ª Fast headless training mode using a grid-based simulator
- ğŸ§  Deep Q-Network (DQN) with experience replay and target networks
- ğŸ¯ Custom reward mechanism encouraging spatial exploration
- ğŸ“ˆ Saved model evaluation and training visualization

---

## ğŸ§± Project Structure
PaintBattleDQL/
â”œâ”€â”€ websocket.py
â”œâ”€â”€ dql.py
â”œâ”€â”€ headless_battle_painters.py
â”œâ”€â”€ headless_dql.py
â”œâ”€â”€ index.html
â”œâ”€â”€ training_coverage.csv
â”œâ”€â”€ js/
â”‚   â”œâ”€â”€ game.js
â”‚   â”œâ”€â”€ gameState.js
â”‚   â”œâ”€â”€ main.js
â”‚   â”œâ”€â”€ object.js
â”‚   â”œâ”€â”€ pickup.js
â”‚   â”œâ”€â”€ rl-agent.js
â”‚   â””â”€â”€ vector.js
â”œâ”€â”€ snd/
â”‚   â”œâ”€â”€ game.mp3
â”‚   â””â”€â”€ mainmenu.mp3
â”œâ”€â”€ img/
â”‚   â”œâ”€â”€ brush.png
â”‚   â””â”€â”€ ... other .png files
â”œâ”€â”€ css/
â”‚   â”œâ”€â”€ main.css
â”‚   â””â”€â”€ main.less
â”œâ”€â”€ battle_painter_model_315_64.pt      # Best model after training
â”œâ”€â”€ annotated_group_13_paintbattle_dql-1.pdf
â””â”€â”€ README.md


---

## ğŸ§  How It Works

### 1. WebSocket Integration

- Modified the PaintBattle game to allow control via WebSocket
- Agent sends actions (left, right, forward); game returns states
- Supports both human and agent play modes

### 2. RL Agent (DQL)

- Implemented in PyTorch (`dql.py`)
- 9-dimensional state vector (position, angle, canvas coverage, etc.)
- Uses Îµ-greedy strategy, replay buffer, and target Q-network

### 3. Headless Simulation (Fast Training)

- `headless_battle_painters.py` simulates painting logic using grids
- Faster training without rendering
- Reward = canvas coverage + density-based exploration

---

## ğŸ§ª Running the Project

### ğŸ” Headless Mode (Recommended for Training)

```bash
python headless_battle_painters.py  # Terminal 1

Keep it running

Then in a second terminal:
python headless_dql.py              # Terminal 2

ğŸ•¸ï¸ Browser Mode (Live Game)

1. Start WebSocket server:
python websocket.py

2. Open index.html in a browser

3. Run the agent:
python dql.py

ğŸ§ª Inference Mode

To run a trained agent:
python dql.py --mode inference --model_path models/best_model.pth

ğŸ“š Future Work

Multi-agent training (competitive/cooperative)
Temporal modeling with LSTMs
Double DQN / Dueling DQN
Power-ups, dynamic hazards
Hyperparameter tuning with Ray Tune

ğŸ‘¥ Authors

Prakhar Dubey â€“ RL agent, headless simulation, codebase structuring
Zarin Tasnim Biash â€“ WebSocket integration, training setup, documentation

ğŸ“„ Report

Full academic report: annotated-group_13_paintbattle_dql-1.pdf

Includes:

Architecture diagrams
Reward analysis

Training results and plots
